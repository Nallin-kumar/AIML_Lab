{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1) Implement  the bagging based Ensemble Model using CART as base learner . NO: of baselearner = 100 .Use cross validation as the model estimation method"
      ],
      "metadata": {
        "id": "LandMF9tplK-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kmOAg9gLirQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2832e297-8621-40be-e646-e5f608b20d88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "\n",
        "#change 'base_estimator'to'estimator'\n",
        "model = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=7)\n",
        "\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average Accuracy is \", average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKKgI3Z4jqZc",
        "outputId": "9ee69437-da30-458e-9e81-acf1a2da3059"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy is  0.7578263841421736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Implement the AdaBoost Ensemble model for classification using 10 base learners and cross validation"
      ],
      "metadata": {
        "id": "BVRfuVe9t7D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQqAm-fepqY_",
        "outputId": "ce38a98c-eb3c-4f2d-eabc-92649dca5311"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "\n",
        "num_trees = 100\n",
        "\n",
        "model = AdaBoostClassifier(n_estimators=num_trees, random_state=7)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average Accuracy is \",average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jTMJWQirkIY",
        "outputId": "0937ba2c-368a-44aa-f2cd-c778eb408dbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy is  0.7578605604921395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3)Implement the Bagging based Ensemble Model using k-Nearest Neighbor Classifier as base learner =100 .Use cross validation as the model estimation method\n"
      ],
      "metadata": {
        "id": "jQGi2Di4r2RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg','pass','pres','skin','test','mass','pedi','age','class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH_oQA_5tAVT",
        "outputId": "f8960085-1911-4904-832d-ed4cec23bf20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "knn=KNeighborsClassifier()\n",
        "num_learners = 100\n",
        "\n",
        "model = BaggingClassifier(estimator=knn, n_estimators=num_learners, random_state=7)\n",
        "\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average Accuracy is\",average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgv190gUuWvj",
        "outputId": "0d9b60be-2665-4af7-d403-342041728a48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy is 0.7188140806561858\n"
          ]
        }
      ]
    }
  ]
}